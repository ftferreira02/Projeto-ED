{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Count of query terms aproximate number of results</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anos</th>\n",
       "      <th>Tesla</th>\n",
       "      <th>carro elétrico</th>\n",
       "      <th>Renault Zoe</th>\n",
       "      <th>emissão zero</th>\n",
       "      <th>mobilidade sustentável</th>\n",
       "      <th>Tesla Model 3</th>\n",
       "      <th>Tesla Model Y</th>\n",
       "      <th>poluição do ar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>78</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015</td>\n",
       "      <td>17580</td>\n",
       "      <td>6660</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>266</td>\n",
       "      <td>6432</td>\n",
       "      <td>6477</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016</td>\n",
       "      <td>62888</td>\n",
       "      <td>14418</td>\n",
       "      <td>11128</td>\n",
       "      <td>2456</td>\n",
       "      <td>1468</td>\n",
       "      <td>25668</td>\n",
       "      <td>27148</td>\n",
       "      <td>16876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "      <td>113383</td>\n",
       "      <td>5858</td>\n",
       "      <td>28044</td>\n",
       "      <td>1518</td>\n",
       "      <td>1765</td>\n",
       "      <td>27161</td>\n",
       "      <td>31919</td>\n",
       "      <td>7688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018</td>\n",
       "      <td>75352</td>\n",
       "      <td>20763</td>\n",
       "      <td>13389</td>\n",
       "      <td>1703</td>\n",
       "      <td>1883</td>\n",
       "      <td>29279</td>\n",
       "      <td>29280</td>\n",
       "      <td>4870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019</td>\n",
       "      <td>42978</td>\n",
       "      <td>18578</td>\n",
       "      <td>7804</td>\n",
       "      <td>6156</td>\n",
       "      <td>8813</td>\n",
       "      <td>23268</td>\n",
       "      <td>23668</td>\n",
       "      <td>14241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2020</td>\n",
       "      <td>34814</td>\n",
       "      <td>21279</td>\n",
       "      <td>13125</td>\n",
       "      <td>14241</td>\n",
       "      <td>21279</td>\n",
       "      <td>12873</td>\n",
       "      <td>13753</td>\n",
       "      <td>16561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021</td>\n",
       "      <td>17</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    anos   Tesla  carro elétrico  Renault Zoe  emissão zero  \\\n",
       "0   2010       0               0            0             0   \n",
       "1   2011       0               0            0             5   \n",
       "2   2012       1               0            0            11   \n",
       "3   2013       0               0            0            36   \n",
       "4   2014      78              47            0           103   \n",
       "5   2015   17580            6660            0           250   \n",
       "6   2016   62888           14418        11128          2456   \n",
       "7   2017  113383            5858        28044          1518   \n",
       "8   2018   75352           20763        13389          1703   \n",
       "9   2019   42978           18578         7804          6156   \n",
       "10  2020   34814           21279        13125         14241   \n",
       "11  2021      17               7            1            10   \n",
       "12  2022       0               0            0             0   \n",
       "\n",
       "    mobilidade sustentável  Tesla Model 3  Tesla Model Y  poluição do ar  \n",
       "0                        0              0              0               0  \n",
       "1                        0              0              0               6  \n",
       "2                        0              0              0               7  \n",
       "3                       19              0              0              73  \n",
       "4                        9              0              0             452  \n",
       "5                      266           6432           6477            1992  \n",
       "6                     1468          25668          27148           16876  \n",
       "7                     1765          27161          31919            7688  \n",
       "8                     1883          29279          29280            4870  \n",
       "9                     8813          23268          23668           14241  \n",
       "10                   21279          12873          13753           16561  \n",
       "11                      11              2              2               8  \n",
       "12                       0              0              0               0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urlparse\n",
    "import time\n",
    "\n",
    "def resultados_por_ano_2(query_term):\n",
    "    sites = 'publico.pt,sapo.pt,jn.pt,observador.pt,expresso.pt'\n",
    "\n",
    "    resultados = []\n",
    "    titulos = []\n",
    "    for i in range(2010, 2023):\n",
    "        data = [int(f\"{i}0101\"), int(f\"{i}1231\")]\n",
    "        \n",
    "\n",
    "        site= f\"https://arquivo.pt/textsearch?q={query_term}&prettyPrint=false&from={data[0]}&to={data[1]}&siteSearch={sites}\"\n",
    "        json = requests.get(site).json()[\"response_items\"]\n",
    "        content = requests.get(site).json()\n",
    "        resultados.append(content['estimated_nr_results'])\n",
    "        # print(f\"{query_term}, {i}, ok\", end=\" | \")\n",
    "        #try:\n",
    "        #    print(json[0][\"linkToExtractedText\"])\n",
    "        #except:\n",
    "        #    pass\n",
    "\n",
    "    return resultados\n",
    "\n",
    "df = pd.DataFrame({\"anos\": list(range(2010, 2023))})\n",
    "# Query terms to search for\n",
    "query_terms = [\n",
    "    \"Tesla\", \"carro elétrico\", \"Renault Zoe\",\n",
    "    \"emissão zero\",\n",
    "    \"mobilidade sustentável\", \"Tesla Model 3\", \"Tesla Model Y\",\"poluição do ar\" \n",
    "]\n",
    "for term in query_terms:\n",
    "    df[term] = resultados_por_ano_2(term)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Code for webscraping websites</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FF\\miniconda3\\envs\\fcd\\Lib\\html\\parser.py:171: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  k = self.parse_starttag(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing Tesla\n",
      "Finished processing carro elétrico\n",
      "Finished processing Renault Zoe\n",
      "Finished processing emissão zero\n",
      "Finished processing mobilidade sustentável\n",
      "Finished processing Tesla Model 3\n",
      "Finished processing Tesla Model Y\n",
      "Finished processing poluição do ar\n",
      "query_term  Renault Zoe  Tesla  Tesla Model 3  Tesla Model Y  carro elétrico  \\\n",
      "year                                                                           \n",
      "2011                  0      0              0              0               0   \n",
      "2012                  0      1              0              0               0   \n",
      "2013                  0      0              0              0               0   \n",
      "2014                  0     49              0              0              22   \n",
      "2015                  0     32             39             35              47   \n",
      "2016                 50     48             48             45              48   \n",
      "2017                 47     44             47             43              48   \n",
      "2018                 49     42             48             47              49   \n",
      "2019                 50     50             50             48              50   \n",
      "2020                 49     42             44             42              46   \n",
      "2021                  1     14              2              2               7   \n",
      "\n",
      "query_term  emissão zero  mobilidade sustentável  poluição do ar  \n",
      "year                                                              \n",
      "2011                   2                       0               2  \n",
      "2012                   8                       0               3  \n",
      "2013                  18                       9              21  \n",
      "2014                  23                       6              49  \n",
      "2015                  48                      48              48  \n",
      "2016                  49                      50              48  \n",
      "2017                  46                      42              47  \n",
      "2018                  50                      50              49  \n",
      "2019                  50                      50              50  \n",
      "2020                  50                      48              50  \n",
      "2021                   8                      10               7  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>query_term</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>extracted_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>PUBLICO.PT</td>\n",
       "      <td>http://publico.pt/</td>\n",
       "      <td>[Os leitores são a força e a vida dos jornais....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>A Tesla vai instalar postos de super carregame...</td>\n",
       "      <td>http://observador.pt/2014/09/11/tesla-vai-inst...</td>\n",
       "      <td>[Rádio, Apoie o jornalismo independente e leia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014</td>\n",
       "      <td>Tesla</td>\n",
       "      <td></td>\n",
       "      <td>http://observador.pt/2014/09/11/tesla-vai-inst...</td>\n",
       "      <td>[Rádio, Apoie o jornalismo independente e leia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>Pedro Esteves - Observador</td>\n",
       "      <td>http://observador.pt/perfil/pesteves/</td>\n",
       "      <td>[Rádio, Apoie o jornalismo independente e leia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>Pedro Esteves - 2/10455 - Observador</td>\n",
       "      <td>http://observador.pt/perfil/pesteves/page/2/</td>\n",
       "      <td>[Rádio, Apoie o jornalismo independente e leia...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year query_term                                              title  \\\n",
       "0  2012      Tesla                                         PUBLICO.PT   \n",
       "1  2014      Tesla  A Tesla vai instalar postos de super carregame...   \n",
       "2  2014      Tesla                                                      \n",
       "3  2014      Tesla                         Pedro Esteves - Observador   \n",
       "4  2014      Tesla               Pedro Esteves - 2/10455 - Observador   \n",
       "\n",
       "                                                 url  \\\n",
       "0                                 http://publico.pt/   \n",
       "1  http://observador.pt/2014/09/11/tesla-vai-inst...   \n",
       "2  http://observador.pt/2014/09/11/tesla-vai-inst...   \n",
       "3              http://observador.pt/perfil/pesteves/   \n",
       "4       http://observador.pt/perfil/pesteves/page/2/   \n",
       "\n",
       "                                      extracted_text  \n",
       "0  [Os leitores são a força e a vida dos jornais....  \n",
       "1  [Rádio, Apoie o jornalismo independente e leia...  \n",
       "2  [Rádio, Apoie o jornalismo independente e leia...  \n",
       "3  [Rádio, Apoie o jornalismo independente e leia...  \n",
       "4  [Rádio, Apoie o jornalismo independente e leia...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extend the domain-to-CSS mapping to include both CSS classes and multiple HTML elements\n",
    "domain_css_element_map = {\n",
    "    \"publico.pt\": {\"css_class\": None, \"html_elements\": [\"p\",\"h1\"]}, \n",
    "    \"sapo.pt\": {\"css_class\": None, \"html_elements\": [\"p\",\"h1\"]},  \n",
    "    \"jn.pt\": {\"css_class\": None, \"html_elements\": [\"p\", \"h1\"]},  # Extract both <p> and <h1> elements\n",
    "    \"observador.pt\": {\"css_class\": None, \"html_elements\": [\"p\",\"h1\"]},  \n",
    "    \"expresso.pt\": {\"css_class\": None, \"html_elements\": [\"p\",\"h1\"]},  \n",
    "}\n",
    "\n",
    "# Function to normalize the domain (remove 'www.')\n",
    "def normalize_domain(domain):\n",
    "    if domain.startswith(\"www.\"):\n",
    "        return domain[4:]  # Remove 'www.' prefix\n",
    "    return domain\n",
    "\n",
    "# Function to extract text based on either a CSS class or multiple HTML elements\n",
    "def extract_text_by_css_class_or_element(original_url, domain_css_element_map):\n",
    "    try:\n",
    "        # Parse the domain from the URL\n",
    "        parsed_url = urlparse(original_url)\n",
    "        domain = normalize_domain(parsed_url.netloc)  # Normalize the domain\n",
    "        \n",
    "        # Get the extraction rule for this domain from the mapping\n",
    "        extraction_rule = domain_css_element_map.get(domain)\n",
    "        if not extraction_rule:\n",
    "            print(f\"No extraction rule found for domain: {domain}\")\n",
    "            return None\n",
    "        \n",
    "        css_class = extraction_rule.get(\"css_class\")\n",
    "        html_elements = extraction_rule.get(\"html_elements\")\n",
    "\n",
    "        # Set a user-agent to mimic a browser request\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "        }\n",
    "\n",
    "        # Initialize backoff_time\n",
    "        backoff_time = 1  # Start with 1 second\n",
    "        \n",
    "        # Fetch the content of the original page\n",
    "        response = requests.get(original_url, headers=headers)\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200:\n",
    "            # Parse the HTML content\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            text_content = []\n",
    "            \n",
    "            # Extract text based on the CSS class if provided\n",
    "            if css_class:\n",
    "                elements = soup.find_all(class_=css_class)\n",
    "                text_content = [element.get_text(strip=True) for element in elements]\n",
    "            \n",
    "            # Extract text based on the HTML elements if provided\n",
    "            if html_elements:\n",
    "                for element in html_elements:\n",
    "                    elements = soup.find_all(element)\n",
    "                    text_content.extend([elem.get_text(strip=True) for elem in elements])\n",
    "            \n",
    "            return text_content\n",
    "        elif response.status_code == 429:\n",
    "                # print(f\"Too Many Requests (429): {original_url}, sleeping for {backoff_time} seconds\")\n",
    "                time.sleep(backoff_time)\n",
    "                backoff_time = min(backoff_time * 2, 60)  # Increase wait time up to 60 seconds\n",
    "        elif response.status_code == 404:\n",
    "                # print(f\"URL not found (404): {original_url}\")\n",
    "                return None\n",
    "        else:\n",
    "            # print(f\"Failed to retrieve {original_url}: Status Code {response.status_code}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        # print(f\"Error fetching {original_url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to get results from Arquivo.pt API and then filter by text content\n",
    "def resultados_por_ano(query_term, domain_css_element_map):\n",
    "    sites = 'publico.pt,sapo.pt,jn.pt,expresso.pt,observador.pt'\n",
    "    textos_filtrados = []\n",
    "    \n",
    "    for i in range(2010, 2023):  # Loop through each year\n",
    "        data = [int(f\"{i}0101\"), int(f\"{i}1231\")]\n",
    "        site = f\"https://arquivo.pt/textsearch?q={query_term}&prettyPrint=false&from={data[0]}&to={data[1]}&siteSearch={sites}\"\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(site)\n",
    "            content = response.json()\n",
    "            \n",
    "            # For each result, extract text from the original URL\n",
    "            for item in content['response_items']:\n",
    "                original_url = item['originalURL']\n",
    "                extracted_text = extract_text_by_css_class_or_element(original_url, domain_css_element_map)\n",
    "                \n",
    "                if extracted_text:\n",
    "                    # combined_text = \" \".join(extracted_text)  # Combine text into one string\n",
    "                    # # Check if the query term appears in the combined text (case-insensitive)\n",
    "                    # if query_term.lower() in combined_text.lower(): \n",
    "                        textos_filtrados.append({\n",
    "                            \"year\": i,\n",
    "                            \"query_term\": query_term,\n",
    "                            \"title\": item['title'],\n",
    "                            \"url\": original_url,\n",
    "                            \"extracted_text\": extracted_text  # Store the combined text\n",
    "                        })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing year {i} for query {query_term}: {e}\")\n",
    "    \n",
    "    return textos_filtrados\n",
    "\n",
    "# Query terms to search for\n",
    "query_terms = [\n",
    "    \"Tesla\", \"carro elétrico\", \"Renault Zoe\",\n",
    "    \"emissão zero\",\n",
    "    \"mobilidade sustentável\", \"Tesla Model 3\", \"Tesla Model Y\",\"poluição do ar\" \n",
    "]\n",
    "\n",
    "# Dictionary to store filtered texts for each query\n",
    "filtered_texts = []\n",
    "\n",
    "# Loop through each query term and collect data\n",
    "for term in query_terms:\n",
    "    textos_filtrados = resultados_por_ano(term, domain_css_element_map)\n",
    "    filtered_texts.extend(textos_filtrados)\n",
    "    print(f\"Finished processing {term}\")\n",
    "\n",
    "# Convert the filtered texts into a DataFrame\n",
    "df_articles = pd.DataFrame(filtered_texts)\n",
    "\n",
    "# Grouping by year and query term to count the number of articles per year for each term\n",
    "df_article_counts = df_articles.groupby([\"year\", \"query_term\"]).size().unstack(fill_value=0)\n",
    "\n",
    "# Display the article count DataFrame (one column per query term, one row per year)\n",
    "print(df_article_counts)\n",
    "\n",
    "# Save the articles DataFrame to CSV for future analysis if needed\n",
    "df_articles.to_csv(\"extracted_articles.csv\", index=False)\n",
    "\n",
    "# Save the article counts to another CSV\n",
    "df_article_counts.to_csv(\"article_counts_by_year.csv\")\n",
    "\n",
    "df_articles.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
